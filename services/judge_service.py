"""
Judge service for getting feedback on LLM responses
"""
import json
from typing import List

import time
from .types import PromptMessage, AIResponse, Provider
from services import AIServiceFactory   
from database.service_factory import get_database_service
JUDGE_USER_PROMPT = """
Original User Prompt:
---
{user_prompt}
---
AI's Response to evaluate:
---
{original_response}
---
"""

class JudgeService:
    """Service for judging LLM responses"""
    
    def __init__(self, enable_database: bool = True):
        self.factory = AIServiceFactory()
        self.enable_database = enable_database
        self.db_service = get_database_service() if enable_database else None
        
    async def send_to_provider(self, provider: Provider, messages: list[PromptMessage], model: str = None, action: str = None):
        """Send prompt to a specific provider"""
        start_time = time.time()
        response = await self.factory.send_to_provider(provider, messages, model, action)
        response_time = time.time() - start_time
        
        if self.enable_database and self.db_service:
            try:
                await self.db_service.save_conversation(
                    messages=messages,
                    responses=[response],
                    response_times={provider.value: response_time}
                )
            except Exception as e:
                print(f"Failed to save conversation to database: {e}")
        
        return response
        
    async def judge_response(self, provider: str, original_response: str, ui_request: str) -> AIResponse:
        """Judge an LLM response using another LLM"""
        
        user_prompt = JUDGE_USER_PROMPT.format(
            user_prompt=ui_request,
            original_response=original_response
        )
        system_prompt = """ You are an expert evaluator of AI-generated content.
        You will be given a user's prompt and the response generated by an AI model. 
        Your task is to critically evaluate the AI's response based on the user's prompt for a BrainWorkout.
        RATING SCALE ranges from 1 to 5. 1 being the worst and 5 being the best.
        """
        messages = [
            PromptMessage(role="system", content=system_prompt),
            PromptMessage(role="user", content=user_prompt)
        ]

        if provider.value == 'openai':
            return await self.send_to_provider(Provider.OPENAI, messages, action="judge_response")
        elif provider.value == 'anthropic':
            return await self.send_to_provider(Provider.ANTHROPIC, messages, action="judge_response")
        elif provider.value == 'gemini':
            return await self.send_to_provider(Provider.OPENAI, messages)
        else:
            return AIResponse(
                provider="JudgeService",
                content="",
                model="",
                error=f"Unknown provider '{provider}' for judging."
            )
